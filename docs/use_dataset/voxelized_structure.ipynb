{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: Prop3D with 3D Structures (MinkowsiEngine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install prereqs: pytorch and huggingface transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if you need to install. For PyTorch GPU installation, follow the instructions on https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo apt install build-essential python3-dev libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install --user torch ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install -U MinkowskiEngine --install-option=\"--blas=openblas\" -v --no-deps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import MinkowskiEngine as ME\n",
    "import MinkowskiEngine.MinkowskiFunctional as MF\n",
    "from Prop3D.ml.datasets.DistributedDomainStructureDataset import DistributedDomainStructureDataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cath_file = \"/projects/Prop3D/Prop3D-20.h5\"\n",
    "cath_superfamily = \"1/10/10/10\" #Use / instead of .\n",
    "os.environ[\"hs_user\"] = \"prot\"\n",
    "os.environ[\"hs_password\"] = \"prot\"\n",
    "os.environ[\"hs_endpoint\"] = \"http://hsds.pods.virginia.edu\"\n",
    "\n",
    "use_features = ['H', 'HD', 'HS', 'C', 'A', 'N', 'NA', 'NS', 'OA', 'OS', 'F', 'MG', 'P', 'SA', 'S', 'CL', 'CA', 'MN', 'FE', 'ZN', 'BR', 'I', 'Unk_atom']\n",
    "predict_features = ['is_highly_frustrated', 'is_minimally_frustrated', 'has_nuetral_frustration']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define UNET model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(ME.MinkowskiNetwork):\n",
    "\n",
    "    def __init__(self, in_nchannel, out_nchannel, D):\n",
    "        super(UNet, self).__init__(D)\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolution(\n",
    "                in_channels=in_nchannel,\n",
    "                out_channels=8,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(8))\n",
    "\n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolution(\n",
    "                in_channels=8,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(16),\n",
    "        )\n",
    "\n",
    "        self.block3 = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolution(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(32))\n",
    "\n",
    "        self.block3_tr = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolutionTranspose(\n",
    "                in_channels=32,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(16))\n",
    "\n",
    "        self.block2_tr = torch.nn.Sequential(\n",
    "            ME.MinkowskiConvolutionTranspose(\n",
    "                in_channels=32,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                dimension=D),\n",
    "            ME.MinkowskiBatchNorm(16))\n",
    "\n",
    "        self.conv1_tr = ME.MinkowskiConvolution(\n",
    "            in_channels=24,\n",
    "            out_channels=out_nchannel,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            dimension=D)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_s1 = self.block1(x)\n",
    "        out = MF.relu(out_s1)\n",
    "\n",
    "        out_s2 = self.block2(out)\n",
    "        out = MF.relu(out_s2)\n",
    "\n",
    "        out_s4 = self.block3(out)\n",
    "        out = MF.relu(out_s4)\n",
    "\n",
    "        out = MF.relu(self.block3_tr(out))\n",
    "        out = ME.cat(out, out_s2)\n",
    "\n",
    "        out = MF.relu(self.block2_tr(out))\n",
    "        out = ME.cat(out, out_s1)\n",
    "\n",
    "        return self.conv1_tr(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Prop3D datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = DistributedDomainStructureDataset(cath_file, cath_superfamily, use_features=use_features, predict_features=predict_features, split_level=\"S100\")\n",
    "training_loader = torch.utils.data.DataLoader(dataset_train, batch_size=128, shuffle=True, collate_fn=ME.utils.collation.SparseCollation())\n",
    "dataset_val = DistributedDomainStructureDataset(cath_file, cath_superfamily, use_features=use_features, predict_features=predict_features, split_level=\"S100\", validation=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=False, collate_fn=ME.utils.collation.SparseCollation())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(len(use_features), len(predict_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=1e-1,\n",
    "        momentum=0.9,\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(pred, labels, smoothing=True):\n",
    "    \"\"\"Calculate cross entropy loss, apply label smoothing if needed.\"\"\"\n",
    "\n",
    "    labels = labels.contiguous().view(-1)\n",
    "    if smoothing:\n",
    "        eps = 0.2\n",
    "        n_class = pred.size(1)\n",
    "\n",
    "        one_hot = torch.zeros_like(pred).scatter(1, labels.view(-1, 1), 1)\n",
    "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
    "        log_prb = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
    "    else:\n",
    "        loss = F.cross_entropy(pred, labels, reduction=\"mean\")\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    for loader, is_train in [(training_loader, True), (val_loader, False)]:\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(loader):\n",
    "            # Every data instance is an input + label pair\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs, labels=labels)\n",
    "    \n",
    "            # Compute the loss and its gradients\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if is_train:\n",
    "                \n",
    "                loss.backward()\n",
    "\n",
    "                # Adjust learning weights\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "\n",
    "                name = \"TRAIN\"\n",
    "\n",
    "            else:\n",
    "                name = \"VALIDATION\"\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            running_loss += loss\n",
    "            if i%1000==0:\n",
    "                last_loss = running_loss / 1000 # loss per batch\n",
    "                print('  {} batch {} loss: {}'.format(name, i + 1, last_loss))\n",
    "                running_loss = 0\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "nbsphinx": {
   "execute": "never"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
